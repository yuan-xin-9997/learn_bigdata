## 1.Nosql的介绍

Nosql晚于RDMS产生，为了解决RDMS在高并发和海量数据存储上的劣势。



Nosql都是分布式的，扩容方便，性能强。

使用场景： 高并发，海量数据存储。不支持SQL语句，数据结构(RDMS只能是表格)灵活



怎么选： 要用事务，就是RDMS。否则都可以考虑Nosql



缓存： 临时存储。数据丢了也无所谓。



## 2.什么时候用Redis

读缓存：  数据所存储的数据库，读性能有一定的限制，希望在高并发的情况下，满足读性能，就使用Redis将目标数据库的数据缓存一份。客户端只需要读Redis



高并发读写：  需要每秒 百万次读写



缓存： 有一些临时的数据，需要存起来，希望灵活的存储。



## 3.几个概念

Map-Reduce(转换-聚合):   《Map-Reduce: 一种处理大数据的理念》。

		思想：  处理大数据时，应该先使用Map阶段对数据处理成希望计算的格式。

					举例：  单词统计： 

					输入;   I hello hi nice    ----------------->Map -------------------> (I,1),(hello,1),(hi,1),(nice)



					在Reduce阶段，对Map阶段输出的数据，进行聚合。 



----





Dog Cuting(Hadoop之父):  参考这篇论文，使用Java语言开发了一个编程框架。 MapReduce，简称MR

MR编程框架，允许程序员引入MR的包，在Mapper中完成Map阶段的逻辑，在Reducer类中完成Reduce阶段的逻辑。

把Mapper,Reducer，和整个Job的Driver打为一个Jar包，在集群上运行。



在集群上，会启动一种进程，这种进程叫MapTask,里面主要执行Mapper中的逻辑。

					再启动另一种进程，这种进程叫ReduceTask, 只要执行Reducer中的逻辑。



-------

第二代Map-Reduce编程框架:  Tez，Spark。 特点是支持DAG（有向无环图）。



对比：   复杂的处理，如果使用MR实现。

			Job1(Mapper , Reducer) ---->Job2(Mapper,Reducer)

			Tez,Spark  :  Job(map----map--reduce--map)



在Spark中充分利用并行度。执行任务的进程称为Executor，在Executor中，维护一个线程池，在每个线程中，计算一个Task（计算任务）

		Task:  Map阶段的任务

					也可以是Reduce阶段的任务，具体看Task是由哪个算子产生的计算需求导致的。



Map思想：  RDD.map

Reduce思想：  RDD.reduceByKey



在一个Spark的shuffle过程中，前一个阶段(Stage)所运行的Task称为MapTask,主要作用是把计算后的数据写出。

后一个stage所运行的task称为ReduceTask，它的作用是把前一个阶段写入的文件通过shuffle获取，之后再进行聚合处理。



## 4.数据类型随笔

单一值：  要保存的值和key是1:1的关系

					1个人，使用人的ID作为key，一个人只有一个妻子，妻子称为单一值。

					一个人会有多个孩子，1:N ,不适合使用string去存。

					可以把把一个人的多个孩子，转为1个单子值   [孩子1,孩子2,孩子3]  ---> [  json] 



二进制安全： 不必担心由于服务端的编码问题，导致数据乱码。 你发什么，我就存什么！原汁原味！
    举例： Mysql不是二进制安全。	
    客户端 发送 中文 到服务端，只要服务端的表不是 支持中文的字符集(用 了 latin)，发过去的中文，
    就以latin在mysql服务端存储，再读出来，就是乱码。



简单理解： string只能存字符串。可以存储任何以字符串为载体的各种文件类型。

						存对象：  对象序列化为字符串，存到redis。 读取时，反序列化

						存图片，视频：  把图片和视频编码为字符串！



所有 xxxnx的命令，都代表，要操作的那个key在当前的库中不存在，才能执行成功，否则失败！



---------





多值：  要保存的值和key是1:N的关系。

			举例： 一个人会有多个孩子，1:N ,使用List去存。











