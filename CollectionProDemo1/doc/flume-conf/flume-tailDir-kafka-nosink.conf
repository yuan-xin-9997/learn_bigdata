# agent
#a1.source=r1
#a1.channel=c1


# source
#a1.sources.r1.type = TAILDIR
#a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json
#a1.sources.r1.filegroups = f1
#a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*

# channel
#a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
#a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
#a1.channels.c1.kafka.topic = topic_log
# a1.channels.channel1.kafka.consumer.group.id = flume-consumer

# bind
#a1.sources.r1.channels = c1


# agent
a1.sources=r1
a1.channels=c1

# source
a1.sources.r1.type = TAILDIR
a1.sources.r1.positionFile = /opt/module/flume/taildir_position.json
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /opt/module/applog/log/app.*
a1.sources.r1.interceptors=i1
a1.sources.r1.interceptors.i1.type=com.atguigu.flume.interceptor.ETLInterceptor$Builder

# channel
a1.channels.c1.type = org.apache.flume.channel.kafka.KafkaChannel
a1.channels.c1.kafka.bootstrap.servers = hadoop102:9092,hadoop103:9092,hadoop104:9092
a1.channels.c1.kafka.topic = topic_log
a1.channels.c1.parseAsFlumeEvent = false

# bind
a1.sources.r1.channels = c1