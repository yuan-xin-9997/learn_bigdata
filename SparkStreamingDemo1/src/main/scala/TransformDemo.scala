/*
* 无状态运算：每个批次之间是相互独立的，各算各的
  有状态运算：当前批次的计算需要使用到上一个批次运算的结果。在上一个运算的基础上继续运算。（无需要掌握）。因为SparkStreaming
  *         原生的计算方式有很大的弊端，
*           虽然提供了有状态计算的算子，但是没有人用。DStream.xxxStatexxx() SparkStreaming提供的有状态计算算子。
*           后续使用其他的方式解决这个问题。
*
* ------------------------------------------
* select
*   a, xxx(b)  ---UDF（输入1行，输出1行）map
* from xxx
* where xxx    ---filter
* group by     --- reduceByKey | groupByKey
* order by     --- sortBy | sortByKey
* limit x      --- take()
*
*
* ------------------------------------------
* transform:
   Return a new DStream in which each RDD is generated by applying a function on each RDD of 'this' DStream.
   def transform[U: ClassTag](transformFunc: RDD[T] => RDD[U]): DStream[U] = ssc.withScope {
   功能：将DStream[T]中的RDD[T]取出来，调用transformFunc，转换为RDD[U]，封装为DStream[U]
*
*  算子：RDD.map, RDD.filter
*  抽象原语：DStream.map, DStream.filter
*
*  算子远比抽象原语丰富，有些方法算子有，但是抽象原语没有。如果希望使用此类方法，只能将DStream的运算转换为对其中RDD的运算，才能调用RDD的算子
*  算完后再把结果封装为DStream
* */

object TransformDemo {

}
